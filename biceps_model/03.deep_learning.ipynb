{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab0b934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Train-Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Classification Report\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6578403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine important landmarks for plank\n",
    "IMPORTANT_LMS = [\n",
    "    \"NOSE\",\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"RIGHT_ELBOW\",\n",
    "    \"LEFT_ELBOW\",\n",
    "    \"RIGHT_WRIST\",\n",
    "    \"LEFT_WRIST\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "]\n",
    "\n",
    "# Generate all columns of the data frame\n",
    "\n",
    "HEADERS = [\"label\"] # Label column\n",
    "\n",
    "for lm in IMPORTANT_LMS:\n",
    "    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae39287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(dataset_path: str):\n",
    "    '''\n",
    "    Describe dataset\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    print(f\"Headers: {list(data.columns.values)}\")\n",
    "    print(f'Number of rows: {data.shape[0]} \\nNumber of columns: {data.shape[1]}\\n')\n",
    "    print(f\"Labels: \\n{data['label'].value_counts()}\\n\")\n",
    "    print(f\"Missing values: {data.isnull().values.any()}\\n\")\n",
    "    \n",
    "    duplicate = data[data.duplicated()]\n",
    "    print(f\"Duplicate Rows : {len(duplicate.sum(axis=1))}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Remove duplicate rows (optional)\n",
    "def remove_duplicate_rows(dataset_path: str):\n",
    "    '''\n",
    "    Remove duplicated data from the dataset then save it to another files\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    df.to_csv(f\"cleaned_train.csv\", sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "def round_up_metric_results(results) -> list:\n",
    "    '''Round up metrics results such as precision score, recall score, ...'''\n",
    "    return list(map(lambda el: round(el, 3), results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21a840df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v']\n",
      "Number of rows: 979 \n",
      "Number of columns: 37\n",
      "\n",
      "Labels: \n",
      "C    557\n",
      "L    422\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = describe_dataset(\"./train.csv\")\n",
    "\n",
    "# Categorizing label\n",
    "df.loc[df[\"label\"] == \"C\", \"label\"] = 0\n",
    "df.loc[df[\"label\"] == \"L\", \"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b6d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./model/input_scaler.pkl\", \"rb\") as f:\n",
    "    sc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07f91195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling of features\n",
    "x = df.drop(\"label\", axis = 1)\n",
    "x = pd.DataFrame(sc.transform(x))\n",
    "\n",
    "y = df[\"label\"]\n",
    "\n",
    "# # Converting prediction to categorical\n",
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7fb1a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x.values, y_cat, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672d5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Final Results\n",
    "final_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af8991ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model(model):\n",
    "    '''\n",
    "    Describe Model architecture\n",
    "    '''\n",
    "    print(f\"Describe models architecture\")\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        number_of_units = layer.units if hasattr(layer, 'units') else 0\n",
    "\n",
    "        if hasattr(layer, \"activation\"):\n",
    "            print(f\"Layer-{i + 1}: {number_of_units} units, func: \", layer.activation)\n",
    "        else:\n",
    "            print(f\"Layer-{i + 1}: {number_of_units} units, func: None\")\n",
    "\n",
    "\n",
    "def get_best_model(tuner):\n",
    "    '''\n",
    "    Describe and return the best model found from keras tuner\n",
    "    '''\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    describe_model(best_model)\n",
    "\n",
    "    print(\"\\nOther params:\")\n",
    "    ignore_params = [\"tuner\", \"activation\", \"layer\", \"epoch\"]\n",
    "    for param, value in best_hps.values.items():\n",
    "        if not any(word in param for word in ignore_params):\n",
    "            print(f\"{param}: {value}\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f062175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba64cc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 02s]\n",
      "val_accuracy: 0.9948979616165161\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 01m 06s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_3l = kt.Hyperband(\n",
    "    model_3l_builder,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo',\n",
    ")\n",
    "tuner_3l.search(x_train, y_train, validation_data=(x_test, y_test), epochs=10, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ecba789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 448 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-3: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n",
      "Other params:\n",
      "learning_rate: 0.01\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.0872 - accuracy: 0.9668 - val_loss: 4.8449e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.4864e-04 - accuracy: 1.0000 - val_loss: 1.0227e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.8161e-05 - accuracy: 1.0000 - val_loss: 7.1878e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.4436e-05 - accuracy: 1.0000 - val_loss: 5.5778e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8652e-05 - accuracy: 1.0000 - val_loss: 4.3577e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.4721e-05 - accuracy: 1.0000 - val_loss: 3.6508e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.1982e-05 - accuracy: 1.0000 - val_loss: 3.0594e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9.9859e-06 - accuracy: 1.0000 - val_loss: 2.6740e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.5392e-06 - accuracy: 1.0000 - val_loss: 2.2666e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 7.1257e-06 - accuracy: 1.0000 - val_loss: 2.0818e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 6.1487e-06 - accuracy: 1.0000 - val_loss: 1.8270e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.2549e-06 - accuracy: 1.0000 - val_loss: 1.6460e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4.5500e-06 - accuracy: 1.0000 - val_loss: 1.5139e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4.0434e-06 - accuracy: 1.0000 - val_loss: 1.3754e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.5653e-06 - accuracy: 1.0000 - val_loss: 1.2687e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.1665e-06 - accuracy: 1.0000 - val_loss: 1.1638e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.8237e-06 - accuracy: 1.0000 - val_loss: 1.0857e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.5350e-06 - accuracy: 1.0000 - val_loss: 1.0240e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2895e-06 - accuracy: 1.0000 - val_loss: 9.5061e-06 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0674e-06 - accuracy: 1.0000 - val_loss: 9.0039e-06 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8756e-06 - accuracy: 1.0000 - val_loss: 8.5084e-06 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.7065e-06 - accuracy: 1.0000 - val_loss: 8.0232e-06 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.5713e-06 - accuracy: 1.0000 - val_loss: 7.5367e-06 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.4320e-06 - accuracy: 1.0000 - val_loss: 7.2698e-06 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.3145e-06 - accuracy: 1.0000 - val_loss: 6.9967e-06 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.2149e-06 - accuracy: 1.0000 - val_loss: 6.6106e-06 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.1202e-06 - accuracy: 1.0000 - val_loss: 6.3735e-06 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.0386e-06 - accuracy: 1.0000 - val_loss: 6.1035e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 9.6902e-07 - accuracy: 1.0000 - val_loss: 5.8347e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.9626e-07 - accuracy: 1.0000 - val_loss: 5.6505e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.3308e-07 - accuracy: 1.0000 - val_loss: 5.4632e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7.6685e-07 - accuracy: 1.0000 - val_loss: 5.3014e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 7.1722e-07 - accuracy: 1.0000 - val_loss: 5.1233e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 6.6622e-07 - accuracy: 1.0000 - val_loss: 4.9153e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 6.2100e-07 - accuracy: 1.0000 - val_loss: 4.7797e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.7883e-07 - accuracy: 1.0000 - val_loss: 4.5444e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.3818e-07 - accuracy: 1.0000 - val_loss: 4.4428e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.0941e-07 - accuracy: 1.0000 - val_loss: 4.3121e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4.7546e-07 - accuracy: 1.0000 - val_loss: 4.2196e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4.4958e-07 - accuracy: 1.0000 - val_loss: 4.0762e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4.2126e-07 - accuracy: 1.0000 - val_loss: 3.9989e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.9843e-07 - accuracy: 1.0000 - val_loss: 3.8767e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.7513e-07 - accuracy: 1.0000 - val_loss: 3.8116e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.5230e-07 - accuracy: 1.0000 - val_loss: 3.6949e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.3509e-07 - accuracy: 1.0000 - val_loss: 3.6049e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.1637e-07 - accuracy: 1.0000 - val_loss: 3.5428e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.9794e-07 - accuracy: 1.0000 - val_loss: 3.4164e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.8089e-07 - accuracy: 1.0000 - val_loss: 3.3544e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.6734e-07 - accuracy: 1.0000 - val_loss: 3.2777e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.5258e-07 - accuracy: 1.0000 - val_loss: 3.2011e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.3857e-07 - accuracy: 1.0000 - val_loss: 3.1336e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.2624e-07 - accuracy: 1.0000 - val_loss: 3.0619e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 0s 3ms/step - loss: 2.1558e-07 - accuracy: 1.0000 - val_loss: 3.0114e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.0477e-07 - accuracy: 1.0000 - val_loss: 2.9530e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.9335e-07 - accuracy: 1.0000 - val_loss: 2.8879e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.8239e-07 - accuracy: 1.0000 - val_loss: 2.8065e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.7417e-07 - accuracy: 1.0000 - val_loss: 2.7499e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.6503e-07 - accuracy: 1.0000 - val_loss: 2.6934e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.5666e-07 - accuracy: 1.0000 - val_loss: 2.6368e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.4981e-07 - accuracy: 1.0000 - val_loss: 2.5644e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.4159e-07 - accuracy: 1.0000 - val_loss: 2.5541e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.3550e-07 - accuracy: 1.0000 - val_loss: 2.4969e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 1.2850e-07 - accuracy: 1.0000 - val_loss: 2.4641e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.2225e-07 - accuracy: 1.0000 - val_loss: 2.3857e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.1632e-07 - accuracy: 1.0000 - val_loss: 2.3352e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.1038e-07 - accuracy: 1.0000 - val_loss: 2.2993e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.0429e-07 - accuracy: 1.0000 - val_loss: 2.2586e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 1.0033e-07 - accuracy: 1.0000 - val_loss: 2.2415e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 9.5306e-08 - accuracy: 1.0000 - val_loss: 2.1734e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 9.0587e-08 - accuracy: 1.0000 - val_loss: 2.1449e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8.5410e-08 - accuracy: 1.0000 - val_loss: 2.1120e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.1147e-08 - accuracy: 1.0000 - val_loss: 2.0676e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7.7798e-08 - accuracy: 1.0000 - val_loss: 2.0391e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7.4144e-08 - accuracy: 1.0000 - val_loss: 2.0001e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 7.1251e-08 - accuracy: 1.0000 - val_loss: 1.9521e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 6.8206e-08 - accuracy: 1.0000 - val_loss: 1.9278e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 6.5009e-08 - accuracy: 1.0000 - val_loss: 1.8955e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 6.1051e-08 - accuracy: 1.0000 - val_loss: 1.8676e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.8158e-08 - accuracy: 1.0000 - val_loss: 1.8287e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.5874e-08 - accuracy: 1.0000 - val_loss: 1.7952e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.3134e-08 - accuracy: 1.0000 - val_loss: 1.7587e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 5.1155e-08 - accuracy: 1.0000 - val_loss: 1.7387e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4.9328e-08 - accuracy: 1.0000 - val_loss: 1.6979e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4.6892e-08 - accuracy: 1.0000 - val_loss: 1.6852e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4.4761e-08 - accuracy: 1.0000 - val_loss: 1.6444e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 4.2934e-08 - accuracy: 1.0000 - val_loss: 1.6134e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 4.0650e-08 - accuracy: 1.0000 - val_loss: 1.5860e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.8823e-08 - accuracy: 1.0000 - val_loss: 1.5690e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.6691e-08 - accuracy: 1.0000 - val_loss: 1.5325e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.5169e-08 - accuracy: 1.0000 - val_loss: 1.5100e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.3799e-08 - accuracy: 1.0000 - val_loss: 1.4972e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 3.2581e-08 - accuracy: 1.0000 - val_loss: 1.4547e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 3.0602e-08 - accuracy: 1.0000 - val_loss: 1.4650e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.9384e-08 - accuracy: 1.0000 - val_loss: 1.3428e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 2.8318e-08 - accuracy: 1.0000 - val_loss: 1.3227e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.6795e-08 - accuracy: 1.0000 - val_loss: 1.3191e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.5577e-08 - accuracy: 1.0000 - val_loss: 1.2972e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.3750e-08 - accuracy: 1.0000 - val_loss: 1.2875e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 2.2533e-08 - accuracy: 1.0000 - val_loss: 1.2723e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2088332ba90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3l = get_best_model(tuner_3l)\n",
    "model_3l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81b6c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"3_layers\"] = model_3l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80a1be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_5l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de6b65f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 02s]\n",
      "accuracy: 1.0\n",
      "\n",
      "Best accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 01m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "tuner_5l = kt.Hyperband(\n",
    "    model_5l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_2'\n",
    ")\n",
    "\n",
    "tuner_5l.search(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58eb7b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 256 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-3: 320 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-4: 480 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-5: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n",
      "Other params:\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 0.1240 - accuracy: 0.9566 - val_loss: 0.3868 - val_accuracy: 0.9388\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9821 - val_loss: 0.0144 - val_accuracy: 0.9949\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 0.9974 - val_loss: 4.6069e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 6.6957e-05 - accuracy: 1.0000 - val_loss: 2.9244e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.6301e-05 - accuracy: 1.0000 - val_loss: 2.4812e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.7383e-05 - accuracy: 1.0000 - val_loss: 2.2094e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 3.1303e-05 - accuracy: 1.0000 - val_loss: 1.9952e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.7017e-05 - accuracy: 1.0000 - val_loss: 1.8665e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.3667e-05 - accuracy: 1.0000 - val_loss: 1.7727e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.0928e-05 - accuracy: 1.0000 - val_loss: 1.6688e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.8691e-05 - accuracy: 1.0000 - val_loss: 1.5935e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.6855e-05 - accuracy: 1.0000 - val_loss: 1.5486e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.5271e-05 - accuracy: 1.0000 - val_loss: 1.4804e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.3834e-05 - accuracy: 1.0000 - val_loss: 1.4255e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.2673e-05 - accuracy: 1.0000 - val_loss: 1.3888e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.1582e-05 - accuracy: 1.0000 - val_loss: 1.3377e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 1.0552e-05 - accuracy: 1.0000 - val_loss: 1.3136e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 9.6970e-06 - accuracy: 1.0000 - val_loss: 1.2739e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "79/79 [==============================] - 1s 11ms/step - loss: 8.9548e-06 - accuracy: 1.0000 - val_loss: 1.2366e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 8.3408e-06 - accuracy: 1.0000 - val_loss: 1.1978e-05 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 7.7133e-06 - accuracy: 1.0000 - val_loss: 1.1849e-05 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "79/79 [==============================] - 1s 10ms/step - loss: 7.1699e-06 - accuracy: 1.0000 - val_loss: 1.1529e-05 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 6.6860e-06 - accuracy: 1.0000 - val_loss: 1.1396e-05 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 6.2246e-06 - accuracy: 1.0000 - val_loss: 1.1070e-05 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 5.8163e-06 - accuracy: 1.0000 - val_loss: 1.0647e-05 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 5.4065e-06 - accuracy: 1.0000 - val_loss: 1.0548e-05 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 5.1046e-06 - accuracy: 1.0000 - val_loss: 1.0378e-05 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 4.7501e-06 - accuracy: 1.0000 - val_loss: 1.0144e-05 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.5042e-06 - accuracy: 1.0000 - val_loss: 9.8571e-06 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.2083e-06 - accuracy: 1.0000 - val_loss: 9.5618e-06 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.9512e-06 - accuracy: 1.0000 - val_loss: 9.1853e-06 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.6989e-06 - accuracy: 1.0000 - val_loss: 9.0516e-06 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 3.4720e-06 - accuracy: 1.0000 - val_loss: 9.0071e-06 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.2886e-06 - accuracy: 1.0000 - val_loss: 8.8625e-06 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.0971e-06 - accuracy: 1.0000 - val_loss: 8.6007e-06 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 2.9181e-06 - accuracy: 1.0000 - val_loss: 8.0747e-06 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.7535e-06 - accuracy: 1.0000 - val_loss: 7.8463e-06 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.5999e-06 - accuracy: 1.0000 - val_loss: 7.7187e-06 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.4534e-06 - accuracy: 1.0000 - val_loss: 7.4630e-06 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.3425e-06 - accuracy: 1.0000 - val_loss: 7.4581e-06 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.2059e-06 - accuracy: 1.0000 - val_loss: 7.1628e-06 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 2.0784e-06 - accuracy: 1.0000 - val_loss: 6.9593e-06 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.9818e-06 - accuracy: 1.0000 - val_loss: 6.9325e-06 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.8775e-06 - accuracy: 1.0000 - val_loss: 6.5808e-06 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.7723e-06 - accuracy: 1.0000 - val_loss: 6.3778e-06 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.6849e-06 - accuracy: 1.0000 - val_loss: 6.2144e-06 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.6014e-06 - accuracy: 1.0000 - val_loss: 6.1257e-06 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.5137e-06 - accuracy: 1.0000 - val_loss: 5.9823e-06 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.4406e-06 - accuracy: 1.0000 - val_loss: 5.7611e-06 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.3671e-06 - accuracy: 1.0000 - val_loss: 5.6201e-06 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.3001e-06 - accuracy: 1.0000 - val_loss: 5.4986e-06 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.2380e-06 - accuracy: 1.0000 - val_loss: 5.2762e-06 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.1785e-06 - accuracy: 1.0000 - val_loss: 5.1741e-06 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.1211e-06 - accuracy: 1.0000 - val_loss: 5.0508e-06 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.0649e-06 - accuracy: 1.0000 - val_loss: 4.9116e-06 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.0154e-06 - accuracy: 1.0000 - val_loss: 4.7657e-06 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 9.6795e-07 - accuracy: 1.0000 - val_loss: 4.6503e-06 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 9.2121e-07 - accuracy: 1.0000 - val_loss: 4.4649e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8.7387e-07 - accuracy: 1.0000 - val_loss: 4.3889e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 8.3535e-07 - accuracy: 1.0000 - val_loss: 4.3573e-06 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 7.9607e-07 - accuracy: 1.0000 - val_loss: 4.1434e-06 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 7.5740e-07 - accuracy: 1.0000 - val_loss: 4.0516e-06 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 7.2178e-07 - accuracy: 1.0000 - val_loss: 3.9404e-06 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 6.8996e-07 - accuracy: 1.0000 - val_loss: 3.8541e-06 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 6.5678e-07 - accuracy: 1.0000 - val_loss: 3.6894e-06 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 6.2922e-07 - accuracy: 1.0000 - val_loss: 3.6098e-06 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5.9801e-07 - accuracy: 1.0000 - val_loss: 3.5362e-06 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5.7030e-07 - accuracy: 1.0000 - val_loss: 3.4463e-06 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5.4214e-07 - accuracy: 1.0000 - val_loss: 3.3259e-06 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 5.1763e-07 - accuracy: 1.0000 - val_loss: 3.1758e-06 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 4.9510e-07 - accuracy: 1.0000 - val_loss: 3.1253e-06 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.7104e-07 - accuracy: 1.0000 - val_loss: 3.0360e-06 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.4942e-07 - accuracy: 1.0000 - val_loss: 2.8937e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 4.2826e-07 - accuracy: 1.0000 - val_loss: 2.8597e-06 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 4.1045e-07 - accuracy: 1.0000 - val_loss: 2.7770e-06 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 3.9310e-07 - accuracy: 1.0000 - val_loss: 2.6907e-06 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 3.7361e-07 - accuracy: 1.0000 - val_loss: 2.5958e-06 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 3.5991e-07 - accuracy: 1.0000 - val_loss: 2.5223e-06 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.4179e-07 - accuracy: 1.0000 - val_loss: 2.4651e-06 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.2626e-07 - accuracy: 1.0000 - val_loss: 2.3600e-06 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 3.1180e-07 - accuracy: 1.0000 - val_loss: 2.3119e-06 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 2.9703e-07 - accuracy: 1.0000 - val_loss: 2.2232e-06 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.8439e-07 - accuracy: 1.0000 - val_loss: 2.1399e-06 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 2.7084e-07 - accuracy: 1.0000 - val_loss: 2.1520e-06 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.5699e-07 - accuracy: 1.0000 - val_loss: 2.1095e-06 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.4618e-07 - accuracy: 1.0000 - val_loss: 2.0323e-06 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 2.3689e-07 - accuracy: 1.0000 - val_loss: 1.9715e-06 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.2624e-07 - accuracy: 1.0000 - val_loss: 1.9125e-06 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.1543e-07 - accuracy: 1.0000 - val_loss: 1.8359e-06 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 2.0782e-07 - accuracy: 1.0000 - val_loss: 1.8012e-06 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 1.9761e-07 - accuracy: 1.0000 - val_loss: 1.7197e-06 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.8833e-07 - accuracy: 1.0000 - val_loss: 1.6559e-06 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.8011e-07 - accuracy: 1.0000 - val_loss: 1.5939e-06 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.7204e-07 - accuracy: 1.0000 - val_loss: 1.5544e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.6534e-07 - accuracy: 1.0000 - val_loss: 1.5045e-06 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 1.5849e-07 - accuracy: 1.0000 - val_loss: 1.4601e-06 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 1.5164e-07 - accuracy: 1.0000 - val_loss: 1.4230e-06 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.4433e-07 - accuracy: 1.0000 - val_loss: 1.3762e-06 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 1.3870e-07 - accuracy: 1.0000 - val_loss: 1.3434e-06 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 1.3245e-07 - accuracy: 1.0000 - val_loss: 1.2899e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x208856ef5b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5l = get_best_model(tuner_5l)\n",
    "model_5l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52823cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"5_layers\"] = model_5l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7231c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7lD_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_dropout_1 = hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_dropout_2 = hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dropout(rate=hp_dropout_1))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dropout(rate=hp_dropout_2))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1725961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from keras_tuner_dir\\keras_tuner_demo_3\\tuner0.json\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_7lD = kt.Hyperband(\n",
    "    model_7lD_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_3'\n",
    ")\n",
    "tuner_7lD.search(x_train, y_train, epochs=10, callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28eaef8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 448 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-3: 0 units, func: None\n",
      "Layer-4: 192 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-5: 0 units, func: None\n",
      "Layer-6: 128 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n",
      "Other params:\n",
      "dropout_1: 0.30000000000000004\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1802 - accuracy: 0.9195 - val_loss: 0.0290 - val_accuracy: 0.9898\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9936 - val_loss: 0.0324 - val_accuracy: 0.9949\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9949\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 5.4264e-04 - accuracy: 1.0000 - val_loss: 0.0283 - val_accuracy: 0.9949\n",
      "Epoch 5/100\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 2.6396e-04 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9949\n",
      "Epoch 6/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 2.0417e-04 - accuracy: 1.0000 - val_loss: 0.0338 - val_accuracy: 0.9949\n",
      "Epoch 7/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 1.0491e-04 - accuracy: 1.0000 - val_loss: 0.0315 - val_accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20887bfe9a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7lD = get_best_model(tuner_7lD)\n",
    "model_7lD.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72ccc1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"7_layers_with_dropout\"] = model_7lD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3650474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_4 = hp.Int('layer_4', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_5 = hp.Int('layer_5', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_4, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_5, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1df70eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 03s]\n",
      "accuracy: 1.0\n",
      "\n",
      "Best accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 01m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_7l = kt.Hyperband(\n",
    "    model_7l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_6'\n",
    ")\n",
    "tuner_7l.search(x_train, y_train, epochs=10, callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d436d4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 448 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-3: 96 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-4: 320 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-5: 256 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-6: 256 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n",
      "Other params:\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.1056 - accuracy: 0.9604 - val_loss: 4.3986e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0787 - accuracy: 0.9898 - val_loss: 0.0058 - val_accuracy: 0.9949\n",
      "Epoch 3/100\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0107 - accuracy: 0.9936 - val_loss: 0.0392 - val_accuracy: 0.9949\n",
      "Epoch 4/100\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.0158 - val_accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20888efca00>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7l = get_best_model(tuner_7l)\n",
    "model_7l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41dbd083",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"7_layers\"] = model_7l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d270d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_layers: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 448 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-3: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n",
      "5_layers: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 256 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-3: 320 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-4: 480 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-5: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n",
      "7_layers_with_dropout: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 448 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-3: 0 units, func: None\n",
      "Layer-4: 192 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-5: 0 units, func: None\n",
      "Layer-6: 128 units, func:  <function tanh at 0x00000208FEB77D30>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n",
      "7_layers: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-2: 448 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-3: 96 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-4: 320 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-5: 256 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-6: 256 units, func:  <function relu at 0x00000208FEB779D0>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x00000208FEB70F70>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in final_models.items():\n",
    "    print(f\"{name}: \", end=\"\")\n",
    "    describe_model(model)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e41b163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_layers</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[[113, 0], [0, 83]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5_layers</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[1.0, 1.0]</td>\n",
       "      <td>[[113, 0], [0, 83]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7_layers_with_dropout</td>\n",
       "      <td>[0.991, 1.0]</td>\n",
       "      <td>[1.0, 0.988]</td>\n",
       "      <td>[0.996, 0.994]</td>\n",
       "      <td>[[113, 0], [1, 82]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7_layers</td>\n",
       "      <td>[0.991, 1.0]</td>\n",
       "      <td>[1.0, 0.988]</td>\n",
       "      <td>[0.996, 0.994]</td>\n",
       "      <td>[[113, 0], [1, 82]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Precision Score  Recall Score        F1 score  \\\n",
       "0               3_layers      [1.0, 1.0]    [1.0, 1.0]      [1.0, 1.0]   \n",
       "1               5_layers      [1.0, 1.0]    [1.0, 1.0]      [1.0, 1.0]   \n",
       "2  7_layers_with_dropout    [0.991, 1.0]  [1.0, 0.988]  [0.996, 0.994]   \n",
       "3               7_layers    [0.991, 1.0]  [1.0, 0.988]  [0.996, 0.994]   \n",
       "\n",
       "      Confusion Matrix  \n",
       "0  [[113, 0], [0, 83]]  \n",
       "1  [[113, 0], [0, 83]]  \n",
       "2  [[113, 0], [1, 82]]  \n",
       "3  [[113, 0], [1, 82]]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Evaluate model\n",
    "    predict_x = model.predict(x_test, verbose=False) \n",
    "    y_pred_class = np.argmax(predict_x, axis=1)\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_test_class, y_pred_class, labels=[0, 1])\n",
    "    (p_score, r_score, f_score, _) = precision_recall_fscore_support(y_test_class, y_pred_class, labels=[0, 1])\n",
    "    \n",
    "    train_set_results.append(( name, round_up_metric_results(p_score), round_up_metric_results(r_score), round_up_metric_results(f_score), cm ))\n",
    "\n",
    "train_set_results.sort(key=lambda k: sum(k[3]), reverse=True)\n",
    "pd.DataFrame(train_set_results, columns=[\"Model\", \"Precision Score\", \"Recall Score\", \"F1 score\", \"Confusion Matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd818a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers: ['label', 'nose_x', 'nose_y', 'nose_z', 'nose_v', 'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_z', 'left_shoulder_v', 'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_z', 'right_shoulder_v', 'right_elbow_x', 'right_elbow_y', 'right_elbow_z', 'right_elbow_v', 'left_elbow_x', 'left_elbow_y', 'left_elbow_z', 'left_elbow_v', 'right_wrist_x', 'right_wrist_y', 'right_wrist_z', 'right_wrist_v', 'left_wrist_x', 'left_wrist_y', 'left_wrist_z', 'left_wrist_v', 'left_hip_x', 'left_hip_y', 'left_hip_z', 'left_hip_v', 'right_hip_x', 'right_hip_y', 'right_hip_z', 'right_hip_v']\n",
      "Number of rows: 419 \n",
      "Number of columns: 37\n",
      "\n",
      "Labels: \n",
      "L    269\n",
      "C    150\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Missing values: False\n",
      "\n",
      "Duplicate Rows : 0\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "test_df = describe_dataset(\"./test.csv\")\n",
    "\n",
    "# Categorizing label\n",
    "test_df.loc[test_df[\"label\"] == \"C\", \"label\"] = 0\n",
    "test_df.loc[test_df[\"label\"] == \"L\", \"label\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "045a803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling of features\n",
    "test_x = test_df.drop(\"label\", axis = 1)\n",
    "test_x = pd.DataFrame(sc.transform(test_x))\n",
    "\n",
    "test_y = test_df[\"label\"]\n",
    "\n",
    "# # Converting prediction to categorical\n",
    "test_y_cat = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb7c4608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7_layers_with_dropout</td>\n",
       "      <td>[0.629, 0.827]</td>\n",
       "      <td>[0.713, 0.766]</td>\n",
       "      <td>[0.669, 0.795]</td>\n",
       "      <td>[[107, 43], [63, 206]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7_layers</td>\n",
       "      <td>[0.625, 0.905]</td>\n",
       "      <td>[0.867, 0.71]</td>\n",
       "      <td>[0.726, 0.796]</td>\n",
       "      <td>[[130, 20], [78, 191]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5_layers</td>\n",
       "      <td>[0.58, 0.897]</td>\n",
       "      <td>[0.867, 0.651]</td>\n",
       "      <td>[0.695, 0.754]</td>\n",
       "      <td>[[130, 20], [94, 175]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_layers</td>\n",
       "      <td>[0.576, 0.756]</td>\n",
       "      <td>[0.553, 0.773]</td>\n",
       "      <td>[0.565, 0.765]</td>\n",
       "      <td>[[83, 67], [61, 208]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model Precision Score    Recall Score        F1 score  \\\n",
       "0  7_layers_with_dropout  [0.629, 0.827]  [0.713, 0.766]  [0.669, 0.795]   \n",
       "1               7_layers  [0.625, 0.905]   [0.867, 0.71]  [0.726, 0.796]   \n",
       "2               5_layers   [0.58, 0.897]  [0.867, 0.651]  [0.695, 0.754]   \n",
       "3               3_layers  [0.576, 0.756]  [0.553, 0.773]  [0.565, 0.765]   \n",
       "\n",
       "         Confusion Matrix  \n",
       "0  [[107, 43], [63, 206]]  \n",
       "1  [[130, 20], [78, 191]]  \n",
       "2  [[130, 20], [94, 175]]  \n",
       "3   [[83, 67], [61, 208]]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Evaluate model\n",
    "    predict_x = model.predict(test_x, verbose=False) \n",
    "    y_pred_class = np.argmax(predict_x, axis=1)\n",
    "    y_test_class = np.argmax(test_y_cat, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_test_class, y_pred_class, labels=[0, 1])\n",
    "    (p_score, r_score, f_score, _) = precision_recall_fscore_support(y_test_class, y_pred_class, labels=[0, 1])\n",
    "    \n",
    "    test_set_results.append(( name, round_up_metric_results(p_score), round_up_metric_results(r_score), round_up_metric_results(f_score), cm ))\n",
    "\n",
    "test_set_results.sort(key=lambda k: k[1] + k[2] + k[3], reverse=True)\n",
    "pd.DataFrame(test_set_results, columns=[\"Model\", \"Precision Score\", \"Recall Score\", \"F1 score\", \"Confusion Matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2bde4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"7_layers\"].save(\"C:/Users/Alrowad/Exercise-correction/biceps_model/model/bicep_dp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c3b736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in final_models.items():\n",
    "    model.save(f\"C:/Users/Alrowad/Exercise-correction/biceps_model/model/{model_name}.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
