{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b0bfc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Train-Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Classification Report\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd7f858",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPORTANT_LMS = [\n",
    "\"NOSE\",\n",
    "\"LEFT_SHOULDER\",\n",
    "\"RIGHT_SHOULDER\",\n",
    "\"LEFT_HIP\",\n",
    "\"RIGHT_HIP\",\n",
    "\"LEFT_KNEE\",\n",
    "\"RIGHT_KNEE\",\n",
    "\"LEFT_ANKLE\",\n",
    "\"RIGHT_ANKLE\",\n",
    "]\n",
    "\n",
    "# Generate all columns of the data frame\n",
    "\n",
    "HEADERS = [\"label\"] # Label column\n",
    "\n",
    "for lm in IMPORTANT_LMS:\n",
    "    HEADERS += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39a08297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_dataset(dataset_path: str):\n",
    "    '''\n",
    "    Describe dataset\n",
    "    '''\n",
    "\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    print(f\"Headers: {list(data.columns.values)}\")\n",
    "    print(f'Number of rows: {data.shape[0]} \\nNumber of columns: {data.shape[1]}\\n')\n",
    "    print(f\"Labels: \\n{data['label'].value_counts()}\\n\")\n",
    "    print(f\"Missing values: {data.isnull().values.any()}\\n\")\n",
    "    \n",
    "    duplicate = data[data.duplicated()]\n",
    "    print(f\"Duplicate Rows : {len(duplicate.sum(axis=1))}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Remove duplicate rows (optional)\n",
    "def remove_duplicate_rows(dataset_path: str):\n",
    "    '''\n",
    "    Remove duplicated data from the dataset then save it to another files\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv(dataset_path)\n",
    "    df.drop_duplicates(keep=\"first\", inplace=True)\n",
    "    df.to_csv(f\"cleaned_train.csv\", sep=',', encoding='utf-8', index=False)\n",
    "\n",
    "\n",
    "def round_up_metric_results(results) -> list:\n",
    "    '''Round up metrics results such as precision score, recall score, ...'''\n",
    "    return list(map(lambda el: round(el, 3), results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6a0d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8660 \n",
      "Number of columns: 37\n",
      "\n",
      "Labels: \n",
      "0    6935\n",
      "1    1725\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "# Categorizing label\n",
    "df.loc[df[\"label\"] == \"no_error\", \"label\"] = 0\n",
    "df.loc[df[\"label\"] == \"knees_inward_error\", \"label\"] = 1\n",
    "\n",
    "print(f'Number of rows: {df.shape[0]} \\nNumber of columns: {df.shape[1]}\\n')\n",
    "print(f\"Labels: \\n{df['label'].value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ef3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling of features\n",
    "# Dump input scaler\n",
    "with open(\"./model/ki_input_scaler.pkl\", \"rb\") as f2:\n",
    "    sc = pickle.load(f2)\n",
    "\n",
    "x = df.drop(\"label\", axis = 1)\n",
    "x = pd.DataFrame(sc.transform(x))\n",
    "\n",
    "y = df[\"label\"]\n",
    "\n",
    "# # Converting prediction to categorical\n",
    "y_cat = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b54aad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x.values, y_cat, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a1be4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "# Final Results\n",
    "final_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "975b8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model(model):\n",
    "    '''\n",
    "    Describe Model architecture\n",
    "    '''\n",
    "    print(f\"Describe models architecture\")\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        number_of_units = layer.units if hasattr(layer, 'units') else 0\n",
    "\n",
    "        if hasattr(layer, \"activation\"):\n",
    "            print(f\"Layer-{i + 1}: {number_of_units} units, func: \", layer.activation)\n",
    "        else:\n",
    "            print(f\"Layer-{i + 1}: {number_of_units} units, func: None\")\n",
    "            \n",
    "\n",
    "def get_best_model(tuner):\n",
    "    '''\n",
    "    Describe and return the best model found from keras tuner\n",
    "    '''\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    best_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "    describe_model(best_model)\n",
    "\n",
    "    print(\"\\nOther params:\")\n",
    "    ignore_params = [\"tuner\", \"activation\", \"layer\"]\n",
    "    for param, value in best_hps.values.items():\n",
    "        if not any(word in param for word in ignore_params):\n",
    "            print(f\"{param}: {value}\")\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ddf156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_3l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75be63d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 06s]\n",
      "accuracy: 0.8415126800537109\n",
      "\n",
      "Best accuracy So Far: 0.929416835308075\n",
      "Total elapsed time: 00h 01m 28s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_3l = kt.Hyperband(\n",
    "    model_3l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "tuner_3l.search(x_train, y_train, epochs=10, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29d87118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 480 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n",
      "Other params:\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.4014 - accuracy: 0.8279 - val_loss: 0.3680 - val_accuracy: 0.8487\n",
      "Epoch 2/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8587 - val_loss: 0.3293 - val_accuracy: 0.8637\n",
      "Epoch 3/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.2977 - accuracy: 0.8834 - val_loss: 0.2860 - val_accuracy: 0.8776\n",
      "Epoch 4/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.2667 - accuracy: 0.8951 - val_loss: 0.2922 - val_accuracy: 0.8782\n",
      "Epoch 5/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.2482 - accuracy: 0.9052 - val_loss: 0.2760 - val_accuracy: 0.8857\n",
      "Epoch 6/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.2263 - accuracy: 0.9115 - val_loss: 0.2360 - val_accuracy: 0.9047\n",
      "Epoch 7/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.2055 - accuracy: 0.9218 - val_loss: 0.2266 - val_accuracy: 0.9117\n",
      "Epoch 8/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.1854 - accuracy: 0.9290 - val_loss: 0.2198 - val_accuracy: 0.9117\n",
      "Epoch 9/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.1745 - accuracy: 0.9335 - val_loss: 0.2016 - val_accuracy: 0.9209\n",
      "Epoch 10/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.1598 - accuracy: 0.9368 - val_loss: 0.2020 - val_accuracy: 0.9192\n",
      "Epoch 11/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.1461 - accuracy: 0.9452 - val_loss: 0.1907 - val_accuracy: 0.9261\n",
      "Epoch 12/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.1361 - accuracy: 0.9456 - val_loss: 0.1807 - val_accuracy: 0.9319\n",
      "Epoch 13/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.1216 - accuracy: 0.9548 - val_loss: 0.1691 - val_accuracy: 0.9319\n",
      "Epoch 14/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.1158 - accuracy: 0.9564 - val_loss: 0.1640 - val_accuracy: 0.9359\n",
      "Epoch 15/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.1058 - accuracy: 0.9597 - val_loss: 0.1862 - val_accuracy: 0.9255\n",
      "Epoch 16/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0992 - accuracy: 0.9628 - val_loss: 0.1689 - val_accuracy: 0.9348\n",
      "Epoch 17/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.9654 - val_loss: 0.1893 - val_accuracy: 0.9336\n",
      "Epoch 18/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0853 - accuracy: 0.9695 - val_loss: 0.1689 - val_accuracy: 0.9296\n",
      "Epoch 19/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.1375 - val_accuracy: 0.9492\n",
      "Epoch 20/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0657 - accuracy: 0.9768 - val_loss: 0.1483 - val_accuracy: 0.9452\n",
      "Epoch 21/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.0670 - accuracy: 0.9752 - val_loss: 0.1460 - val_accuracy: 0.9503\n",
      "Epoch 22/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.0630 - accuracy: 0.9782 - val_loss: 0.1519 - val_accuracy: 0.9428\n",
      "Epoch 23/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0648 - accuracy: 0.9783 - val_loss: 0.1554 - val_accuracy: 0.9469\n",
      "Epoch 24/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0529 - accuracy: 0.9821 - val_loss: 0.1615 - val_accuracy: 0.9411\n",
      "Epoch 25/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0505 - accuracy: 0.9827 - val_loss: 0.1638 - val_accuracy: 0.9452\n",
      "Epoch 26/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0551 - accuracy: 0.9795 - val_loss: 0.1817 - val_accuracy: 0.9388\n",
      "Epoch 27/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0401 - accuracy: 0.9866 - val_loss: 0.1419 - val_accuracy: 0.9527\n",
      "Epoch 28/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0435 - accuracy: 0.9866 - val_loss: 0.1488 - val_accuracy: 0.9584\n",
      "Epoch 29/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0420 - accuracy: 0.9866 - val_loss: 0.2665 - val_accuracy: 0.9342\n",
      "Epoch 30/100\n",
      "693/693 [==============================] - 2s 2ms/step - loss: 0.0615 - accuracy: 0.9825 - val_loss: 0.1392 - val_accuracy: 0.9555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b2e8a8e070>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3l = get_best_model(tuner_3l)\n",
    "model_3l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4ff9666",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"3_layers\"] = model_3l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cc96def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_5l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d789da87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 08s]\n",
      "accuracy: 0.8589780330657959\n",
      "\n",
      "Best accuracy So Far: 0.9590069055557251\n",
      "Total elapsed time: 00h 02m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "tuner_5l = kt.Hyperband(\n",
    "    model_5l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_1'\n",
    ")\n",
    "\n",
    "tuner_5l.search(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca12b694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 160 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 480 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-4: 288 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-5: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n",
      "Other params:\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "693/693 [==============================] - 4s 4ms/step - loss: 0.4117 - accuracy: 0.8246 - val_loss: 0.3732 - val_accuracy: 0.8401\n",
      "Epoch 2/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.3294 - accuracy: 0.8682 - val_loss: 0.3081 - val_accuracy: 0.8799\n",
      "Epoch 3/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2845 - accuracy: 0.8893 - val_loss: 0.2737 - val_accuracy: 0.8834\n",
      "Epoch 4/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2481 - accuracy: 0.9030 - val_loss: 0.2658 - val_accuracy: 0.9001\n",
      "Epoch 5/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2187 - accuracy: 0.9138 - val_loss: 0.2365 - val_accuracy: 0.9047\n",
      "Epoch 6/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1943 - accuracy: 0.9261 - val_loss: 0.2230 - val_accuracy: 0.9076\n",
      "Epoch 7/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1775 - accuracy: 0.9362 - val_loss: 0.2182 - val_accuracy: 0.9169\n",
      "Epoch 8/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1520 - accuracy: 0.9430 - val_loss: 0.1936 - val_accuracy: 0.9267\n",
      "Epoch 9/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1282 - accuracy: 0.9525 - val_loss: 0.1770 - val_accuracy: 0.9376\n",
      "Epoch 10/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1148 - accuracy: 0.9567 - val_loss: 0.1789 - val_accuracy: 0.9324\n",
      "Epoch 11/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.1040 - accuracy: 0.9603 - val_loss: 0.1795 - val_accuracy: 0.9376\n",
      "Epoch 12/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0891 - accuracy: 0.9648 - val_loss: 0.1691 - val_accuracy: 0.9457\n",
      "Epoch 13/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0892 - accuracy: 0.9674 - val_loss: 0.1686 - val_accuracy: 0.9423\n",
      "Epoch 14/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0726 - accuracy: 0.9724 - val_loss: 0.1806 - val_accuracy: 0.9336\n",
      "Epoch 15/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.0648 - accuracy: 0.9769 - val_loss: 0.1826 - val_accuracy: 0.9463\n",
      "Epoch 16/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0756 - accuracy: 0.9737 - val_loss: 0.1699 - val_accuracy: 0.9388\n",
      "Epoch 17/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0669 - accuracy: 0.9773 - val_loss: 0.1815 - val_accuracy: 0.9330\n",
      "Epoch 18/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0568 - accuracy: 0.9792 - val_loss: 0.1761 - val_accuracy: 0.9503\n",
      "Epoch 19/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0539 - accuracy: 0.9804 - val_loss: 0.1405 - val_accuracy: 0.9498\n",
      "Epoch 20/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0524 - accuracy: 0.9809 - val_loss: 0.2167 - val_accuracy: 0.9301\n",
      "Epoch 21/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0572 - accuracy: 0.9804 - val_loss: 0.1735 - val_accuracy: 0.9503\n",
      "Epoch 22/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.0492 - accuracy: 0.9840 - val_loss: 0.1761 - val_accuracy: 0.9503\n",
      "Epoch 23/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0398 - accuracy: 0.9861 - val_loss: 0.1800 - val_accuracy: 0.9503\n",
      "Epoch 24/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0445 - accuracy: 0.9861 - val_loss: 0.2586 - val_accuracy: 0.9359\n",
      "Epoch 25/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.0456 - accuracy: 0.9854 - val_loss: 0.1688 - val_accuracy: 0.9602\n",
      "Epoch 26/100\n",
      "693/693 [==============================] - 4s 5ms/step - loss: 0.0441 - accuracy: 0.9857 - val_loss: 0.2381 - val_accuracy: 0.9394\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b2e9c3e430>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5l = get_best_model(tuner_5l)\n",
    "model_5l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e218a431",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"5_layers\"] = model_5l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d08b19eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7lD_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_dropout_1 = hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_dropout_2 = hp.Float('dropout_2', min_value=0.1, max_value=0.5, step=0.1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dropout(rate=hp_dropout_1))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dropout(rate=hp_dropout_2))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7198049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 13s]\n",
      "accuracy: 0.851760983467102\n",
      "\n",
      "Best accuracy So Far: 0.9461604952812195\n",
      "Total elapsed time: 00h 03m 06s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "def get_early_stopping_callback():\n",
    "    return keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=3\n",
    "    )\n",
    "\n",
    "tuner_7lD = kt.Hyperband(\n",
    "    model_7lD_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_4'\n",
    ")\n",
    "tuner_7lD.search(x_train, y_train, epochs=10, callbacks=[get_early_stopping_callback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79e4f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 160 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 0 units, func: None\n",
      "Layer-4: 352 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-5: 0 units, func: None\n",
      "Layer-6: 256 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n",
      "Other params:\n",
      "dropout_1: 0.1\n",
      "dropout_2: 0.1\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "693/693 [==============================] - 4s 4ms/step - loss: 0.4156 - accuracy: 0.8233 - val_loss: 0.3726 - val_accuracy: 0.8406\n",
      "Epoch 2/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.3456 - accuracy: 0.8597 - val_loss: 0.3326 - val_accuracy: 0.8643\n",
      "Epoch 3/100\n",
      "693/693 [==============================] - 4s 5ms/step - loss: 0.3088 - accuracy: 0.8795 - val_loss: 0.2884 - val_accuracy: 0.8886\n",
      "Epoch 4/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2796 - accuracy: 0.8938 - val_loss: 0.2732 - val_accuracy: 0.8915\n",
      "Epoch 5/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.2480 - accuracy: 0.9029 - val_loss: 0.2486 - val_accuracy: 0.9001\n",
      "Epoch 6/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2282 - accuracy: 0.9127 - val_loss: 0.2646 - val_accuracy: 0.8949\n",
      "Epoch 7/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.2015 - accuracy: 0.9236 - val_loss: 0.2492 - val_accuracy: 0.9065\n",
      "Epoch 8/100\n",
      "693/693 [==============================] - 5s 7ms/step - loss: 0.1905 - accuracy: 0.9270 - val_loss: 0.2333 - val_accuracy: 0.9036\n",
      "Epoch 9/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.1702 - accuracy: 0.9348 - val_loss: 0.2101 - val_accuracy: 0.9157\n",
      "Epoch 10/100\n",
      "693/693 [==============================] - 2s 4ms/step - loss: 0.1554 - accuracy: 0.9417 - val_loss: 0.2120 - val_accuracy: 0.9099\n",
      "Epoch 11/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1464 - accuracy: 0.9441 - val_loss: 0.2109 - val_accuracy: 0.9145\n",
      "Epoch 12/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1384 - accuracy: 0.9449 - val_loss: 0.1890 - val_accuracy: 0.9226\n",
      "Epoch 13/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1258 - accuracy: 0.9519 - val_loss: 0.1836 - val_accuracy: 0.9330\n",
      "Epoch 14/100\n",
      "693/693 [==============================] - 3s 5ms/step - loss: 0.1228 - accuracy: 0.9547 - val_loss: 0.1670 - val_accuracy: 0.9365\n",
      "Epoch 15/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1166 - accuracy: 0.9566 - val_loss: 0.1786 - val_accuracy: 0.9313\n",
      "Epoch 16/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.1105 - accuracy: 0.9576 - val_loss: 0.1632 - val_accuracy: 0.9365\n",
      "Epoch 17/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0979 - accuracy: 0.9630 - val_loss: 0.1867 - val_accuracy: 0.9440\n",
      "Epoch 18/100\n",
      "693/693 [==============================] - 2s 4ms/step - loss: 0.1031 - accuracy: 0.9616 - val_loss: 0.1629 - val_accuracy: 0.9423\n",
      "Epoch 19/100\n",
      "693/693 [==============================] - 2s 3ms/step - loss: 0.0932 - accuracy: 0.9651 - val_loss: 0.1451 - val_accuracy: 0.9492\n",
      "Epoch 20/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0941 - accuracy: 0.9671 - val_loss: 0.1865 - val_accuracy: 0.9342\n",
      "Epoch 21/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0836 - accuracy: 0.9674 - val_loss: 0.1174 - val_accuracy: 0.9555\n",
      "Epoch 22/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0819 - accuracy: 0.9704 - val_loss: 0.1382 - val_accuracy: 0.9532\n",
      "Epoch 23/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0701 - accuracy: 0.9742 - val_loss: 0.1401 - val_accuracy: 0.9492\n",
      "Epoch 24/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0710 - accuracy: 0.9746 - val_loss: 0.1345 - val_accuracy: 0.9521\n",
      "Epoch 25/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0653 - accuracy: 0.9765 - val_loss: 0.1605 - val_accuracy: 0.9463\n",
      "Epoch 26/100\n",
      "693/693 [==============================] - 4s 6ms/step - loss: 0.0678 - accuracy: 0.9750 - val_loss: 0.1610 - val_accuracy: 0.9492\n",
      "Epoch 27/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0726 - accuracy: 0.9745 - val_loss: 0.1204 - val_accuracy: 0.9555\n",
      "Epoch 28/100\n",
      "693/693 [==============================] - 3s 4ms/step - loss: 0.0655 - accuracy: 0.9783 - val_loss: 0.1531 - val_accuracy: 0.9492\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b2ebeed850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7lD = get_best_model(tuner_7lD)\n",
    "model_7lD.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "842e3efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"7_layers_with_dropout\"] = model_7lD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6dc8aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_7l_builder(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(36, input_dim = 36, activation = \"relu\"))\n",
    "\n",
    "    hp_activation = hp.Choice('activation', values=['relu', 'tanh'])\n",
    "    hp_layer_1 = hp.Int('layer_1', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_2 = hp.Int('layer_2', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_3 = hp.Int('layer_3', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_4 = hp.Int('layer_4', min_value=32, max_value=512, step=32)\n",
    "    hp_layer_5 = hp.Int('layer_5', min_value=32, max_value=512, step=32)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.add(Dense(units=hp_layer_1, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_2, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_3, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_4, activation=hp_activation))\n",
    "    model.add(Dense(units=hp_layer_5, activation=hp_activation))\n",
    "    model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp_learning_rate), loss=\"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6cac322f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 19s]\n",
      "accuracy: 0.9577078819274902\n",
      "\n",
      "Best accuracy So Far: 0.9603059887886047\n",
      "Total elapsed time: 00h 02m 59s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_7l = kt.Hyperband(\n",
    "    model_7l_builder,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    directory='keras_tuner_dir',\n",
    "    project_name='keras_tuner_demo_5'\n",
    ")\n",
    "tuner_7l.search(x_train, y_train, epochs=10, callbacks=[keras.callbacks.EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52dde00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 224 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 320 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-4: 320 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-5: 448 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-6: 288 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n",
      "Other params:\n",
      "learning_rate: 0.001\n",
      "Epoch 1/100\n",
      "693/693 [==============================] - 5s 7ms/step - loss: 0.4187 - accuracy: 0.8252 - val_loss: 0.3637 - val_accuracy: 0.8447\n",
      "Epoch 2/100\n",
      "693/693 [==============================] - 5s 7ms/step - loss: 0.3377 - accuracy: 0.8616 - val_loss: 0.3180 - val_accuracy: 0.8695\n",
      "Epoch 3/100\n",
      "693/693 [==============================] - 4s 6ms/step - loss: 0.2984 - accuracy: 0.8803 - val_loss: 0.3135 - val_accuracy: 0.8712\n",
      "Epoch 4/100\n",
      "693/693 [==============================] - 5s 7ms/step - loss: 0.2688 - accuracy: 0.8984 - val_loss: 0.2741 - val_accuracy: 0.8863\n",
      "Epoch 5/100\n",
      "693/693 [==============================] - 6s 8ms/step - loss: 0.2386 - accuracy: 0.9021 - val_loss: 0.2596 - val_accuracy: 0.8886\n",
      "Epoch 6/100\n",
      "693/693 [==============================] - 5s 7ms/step - loss: 0.2059 - accuracy: 0.9174 - val_loss: 0.2929 - val_accuracy: 0.8805\n",
      "Epoch 7/100\n",
      "693/693 [==============================] - 6s 9ms/step - loss: 0.1839 - accuracy: 0.9273 - val_loss: 0.2189 - val_accuracy: 0.9105\n",
      "Epoch 8/100\n",
      "693/693 [==============================] - 6s 9ms/step - loss: 0.1610 - accuracy: 0.9374 - val_loss: 0.2074 - val_accuracy: 0.9215\n",
      "Epoch 9/100\n",
      "693/693 [==============================] - 6s 9ms/step - loss: 0.1451 - accuracy: 0.9440 - val_loss: 0.2269 - val_accuracy: 0.9122\n",
      "Epoch 10/100\n",
      "693/693 [==============================] - 5s 7ms/step - loss: 0.1350 - accuracy: 0.9462 - val_loss: 0.1604 - val_accuracy: 0.9336\n",
      "Epoch 11/100\n",
      "693/693 [==============================] - 4s 6ms/step - loss: 0.1154 - accuracy: 0.9563 - val_loss: 0.1619 - val_accuracy: 0.9417\n",
      "Epoch 12/100\n",
      "693/693 [==============================] - 4s 6ms/step - loss: 0.0991 - accuracy: 0.9622 - val_loss: 0.1527 - val_accuracy: 0.9417\n",
      "Epoch 13/100\n",
      "693/693 [==============================] - 4s 6ms/step - loss: 0.1048 - accuracy: 0.9619 - val_loss: 0.1965 - val_accuracy: 0.9376\n",
      "Epoch 14/100\n",
      "693/693 [==============================] - 6s 8ms/step - loss: 0.0990 - accuracy: 0.9645 - val_loss: 0.2017 - val_accuracy: 0.9388\n",
      "Epoch 15/100\n",
      "693/693 [==============================] - 5s 8ms/step - loss: 0.0799 - accuracy: 0.9710 - val_loss: 0.1865 - val_accuracy: 0.9463\n",
      "Epoch 16/100\n",
      "693/693 [==============================] - 5s 7ms/step - loss: 0.0763 - accuracy: 0.9710 - val_loss: 0.1822 - val_accuracy: 0.9238\n",
      "Epoch 17/100\n",
      "693/693 [==============================] - 5s 8ms/step - loss: 0.0820 - accuracy: 0.9708 - val_loss: 0.2377 - val_accuracy: 0.9521\n",
      "Epoch 18/100\n",
      "693/693 [==============================] - 7s 10ms/step - loss: 0.0796 - accuracy: 0.9719 - val_loss: 0.1520 - val_accuracy: 0.9382\n",
      "Epoch 19/100\n",
      "693/693 [==============================] - 7s 10ms/step - loss: 0.0610 - accuracy: 0.9778 - val_loss: 0.1925 - val_accuracy: 0.9405\n",
      "Epoch 20/100\n",
      "693/693 [==============================] - 7s 10ms/step - loss: 0.0648 - accuracy: 0.9789 - val_loss: 0.2009 - val_accuracy: 0.9428\n",
      "Epoch 21/100\n",
      "693/693 [==============================] - 6s 8ms/step - loss: 0.0788 - accuracy: 0.9769 - val_loss: 0.2165 - val_accuracy: 0.9405\n",
      "Epoch 22/100\n",
      "693/693 [==============================] - 6s 9ms/step - loss: 0.0663 - accuracy: 0.9778 - val_loss: 0.1870 - val_accuracy: 0.9521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b2ec143190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7l = get_best_model(tuner_7l)\n",
    "model_7l.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7832a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"7_layers\"] = model_7l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd3aab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_layers: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 480 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n",
      "5_layers: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 160 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 480 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-4: 288 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-5: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n",
      "7_layers_with_dropout: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 160 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 0 units, func: None\n",
      "Layer-4: 352 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-5: 0 units, func: None\n",
      "Layer-6: 256 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n",
      "7_layers: Describe models architecture\n",
      "Layer-1: 36 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-2: 224 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-3: 320 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-4: 320 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-5: 448 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-6: 288 units, func:  <function relu at 0x000002B2E3C548B0>\n",
      "Layer-7: 2 units, func:  <function softmax at 0x000002B2E3C4CE50>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in final_models.items():\n",
    "    print(f\"{name}: \", end=\"\")\n",
    "    describe_model(model)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bc18e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_layers</td>\n",
       "      <td>[0.975, 0.879, 0.0]</td>\n",
       "      <td>[0.97, 0.897, 0.0]</td>\n",
       "      <td>[0.972, 0.888, 0.0]</td>\n",
       "      <td>[[1351, 42, 0], [35, 304, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7_layers</td>\n",
       "      <td>[0.976, 0.86, 0.0]</td>\n",
       "      <td>[0.964, 0.903, 0.0]</td>\n",
       "      <td>[0.97, 0.881, 0.0]</td>\n",
       "      <td>[[1343, 50, 0], [33, 306, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7_layers_with_dropout</td>\n",
       "      <td>[0.961, 0.896, 0.0]</td>\n",
       "      <td>[0.976, 0.838, 0.0]</td>\n",
       "      <td>[0.969, 0.866, 0.0]</td>\n",
       "      <td>[[1360, 33, 0], [55, 284, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_layers</td>\n",
       "      <td>[0.969, 0.827, 0.0]</td>\n",
       "      <td>[0.955, 0.873, 0.0]</td>\n",
       "      <td>[0.962, 0.849, 0.0]</td>\n",
       "      <td>[[1331, 62, 0], [43, 296, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      Precision Score         Recall Score  \\\n",
       "0               3_layers  [0.975, 0.879, 0.0]   [0.97, 0.897, 0.0]   \n",
       "1               7_layers   [0.976, 0.86, 0.0]  [0.964, 0.903, 0.0]   \n",
       "2  7_layers_with_dropout  [0.961, 0.896, 0.0]  [0.976, 0.838, 0.0]   \n",
       "3               5_layers  [0.969, 0.827, 0.0]  [0.955, 0.873, 0.0]   \n",
       "\n",
       "              F1 score                          Confusion Matrix  \n",
       "0  [0.972, 0.888, 0.0]  [[1351, 42, 0], [35, 304, 0], [0, 0, 0]]  \n",
       "1   [0.97, 0.881, 0.0]  [[1343, 50, 0], [33, 306, 0], [0, 0, 0]]  \n",
       "2  [0.969, 0.866, 0.0]  [[1360, 33, 0], [55, 284, 0], [0, 0, 0]]  \n",
       "3  [0.962, 0.849, 0.0]  [[1331, 62, 0], [43, 296, 0], [0, 0, 0]]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Evaluate model\n",
    "    predict_x = model.predict(x_test, verbose=False) \n",
    "    y_pred_class = np.argmax(predict_x, axis=1)\n",
    "    y_test_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    (p_score, r_score, f_score, _) = precision_recall_fscore_support(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    \n",
    "    train_set_results.append(( name, round_up_metric_results(p_score), round_up_metric_results(r_score), round_up_metric_results(f_score), cm ))\n",
    "\n",
    "train_set_results.sort(key=lambda k: sum(k[3]), reverse=True)\n",
    "pd.DataFrame(train_set_results, columns=[\"Model\", \"Precision Score\", \"Recall Score\", \"F1 score\", \"Confusion Matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "877235af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8660 \n",
      "Number of columns: 37\n",
      "\n",
      "Labels: \n",
      "0    6935\n",
      "1    1725\n",
      "Name: label, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "test_df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "# Categorizing label\n",
    "test_df.loc[test_df[\"label\"] == \"no_error\", \"label\"] = 0\n",
    "test_df.loc[test_df[\"label\"] == \"knees_inward_error\", \"label\"] = 1\n",
    "\n",
    "print(f'Number of rows: {test_df.shape[0]} \\nNumber of columns: {test_df.shape[1]}\\n')\n",
    "print(f\"Labels: \\n{test_df['label'].value_counts()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9740aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaling of features\n",
    "test_x = test_df.drop(\"label\", axis = 1)\n",
    "test_x = pd.DataFrame(sc.transform(test_x))\n",
    "\n",
    "test_y = test_df[\"label\"]\n",
    "\n",
    "# # Converting prediction to categorical\n",
    "test_y_cat = to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f4d38d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision Score</th>\n",
       "      <th>Recall Score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3_layers</td>\n",
       "      <td>[0.993, 0.961, 0.0]</td>\n",
       "      <td>[0.99, 0.972, 0.0]</td>\n",
       "      <td>[0.992, 0.966, 0.0]</td>\n",
       "      <td>[[6867, 68, 0], [49, 1676, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7_layers</td>\n",
       "      <td>[0.992, 0.932, 0.0]</td>\n",
       "      <td>[0.983, 0.968, 0.0]</td>\n",
       "      <td>[0.987, 0.95, 0.0]</td>\n",
       "      <td>[[6814, 121, 0], [55, 1670, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7_layers_with_dropout</td>\n",
       "      <td>[0.983, 0.959, 0.0]</td>\n",
       "      <td>[0.99, 0.93, 0.0]</td>\n",
       "      <td>[0.986, 0.945, 0.0]</td>\n",
       "      <td>[[6867, 68, 0], [120, 1605, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5_layers</td>\n",
       "      <td>[0.986, 0.898, 0.0]</td>\n",
       "      <td>[0.973, 0.945, 0.0]</td>\n",
       "      <td>[0.98, 0.921, 0.0]</td>\n",
       "      <td>[[6750, 185, 0], [95, 1630, 0], [0, 0, 0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      Precision Score         Recall Score  \\\n",
       "0               3_layers  [0.993, 0.961, 0.0]   [0.99, 0.972, 0.0]   \n",
       "1               7_layers  [0.992, 0.932, 0.0]  [0.983, 0.968, 0.0]   \n",
       "2  7_layers_with_dropout  [0.983, 0.959, 0.0]    [0.99, 0.93, 0.0]   \n",
       "3               5_layers  [0.986, 0.898, 0.0]  [0.973, 0.945, 0.0]   \n",
       "\n",
       "              F1 score                            Confusion Matrix  \n",
       "0  [0.992, 0.966, 0.0]   [[6867, 68, 0], [49, 1676, 0], [0, 0, 0]]  \n",
       "1   [0.987, 0.95, 0.0]  [[6814, 121, 0], [55, 1670, 0], [0, 0, 0]]  \n",
       "2  [0.986, 0.945, 0.0]  [[6867, 68, 0], [120, 1605, 0], [0, 0, 0]]  \n",
       "3   [0.98, 0.921, 0.0]  [[6750, 185, 0], [95, 1630, 0], [0, 0, 0]]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_results = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Evaluate model\n",
    "    predict_x = model.predict(test_x, verbose=False) \n",
    "    y_pred_class = np.argmax(predict_x, axis=1)\n",
    "    y_test_class = np.argmax(test_y_cat, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    (p_score, r_score, f_score, _) = precision_recall_fscore_support(y_test_class, y_pred_class, labels=[0, 1, 2])\n",
    "    \n",
    "    test_set_results.append(( name, round_up_metric_results(p_score), round_up_metric_results(r_score), round_up_metric_results(f_score), cm ))\n",
    "\n",
    "test_set_results.sort(key=lambda k: sum(k[3]), reverse=True)\n",
    "pd.DataFrame(test_set_results, columns=[\"Model\", \"Precision Score\", \"Recall Score\", \"F1 score\", \"Confusion Matrix\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aca67b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models[\"3_layers\"].save(\"./model/ki_dp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60b03480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, model in final_models.items():\n",
    "    model.save(f\"./model/{model_name}.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
